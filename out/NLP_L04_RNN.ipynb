{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ª–µ–∫—Ü–∏–∏ –º—ã –Ω–∞—É—á–∏–ª–∏—Å—å —Å—Ç—Ä–æ–∏—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏. –ü—Ä–∏ —ç—Ç–æ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–ª–æ —Å–æ–±–æ–π —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–£ —ç—Ç–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –µ—Å—Ç—å –≤–∞–∂–Ω—ã–π –º–∏–Ω—É—Å: –æ–Ω –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç, —á—Ç–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–∞–∂–Ω–∞ –∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –¢–µ–º —Å–∞–º—ã–º, —Ç–µ–∫—Å—Ç—ã **¬´–Ø –Ω–µ –ª—é–±–ª—é ML¬ª** –∏ **¬´–Ø –ª—é–±–ª—é –Ω–µ ML¬ª** –ø–æ–ª—É—á–∞—é—Ç **–æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ** –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏, —Ç–æ –µ—Å—Ç—å –ø–æ —Ö–æ–¥—É **—Ç–µ—Ä—è–µ—Ç—Å—è** —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è.\n",
    "\n",
    "–¢–µ–∫—Å—Ç –ø–∏—à–µ—Ç—Å—è –∏ —á–∏—Ç–∞–µ—Ç—Å—è **–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ**. –ù–∞–º –º–æ–∂–µ—Ç –ø–æ–∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ —ç—Ç–æ —Å—Ç–æ–∏—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å: –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –æ–±—Ä–∞—â–∞—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º, –∫–∞–∫ –∫ –µ–≥–æ **–∫–æ–Ω—Ç–µ–∫—Å—Ç—É**.\n",
    "\n",
    "–î–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è **—Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (recurrent neural networks, RNN)**. –û–Ω–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –≤ —à–∏—Ä–æ–∫–æ–º –ø–µ—Ä–µ—á–Ω–µ –∑–∞–¥–∞—á: –æ—Ç **—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏** –¥–æ **–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–µ–π** –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º.\n",
    "\n",
    "–≠—Ç–∏ –∑–∞–¥–∞—á–∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å **–∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º** –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ–¥–Ω–æ–π —á–∞—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥—Ä—É–≥–∏—Ö —á–∞—Å—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/sequence_data.png\" width=\"1000\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–° –º–æ–¥–µ–ª—è–º–∏ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∫–æ–Ω–∫—É—Ä–∏—Ä—É—é—Ç –º–æ–¥–µ–ª–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ **–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä** (–ø–æ–¥—Ä–æ–±–Ω–µ–µ –≤ —Å–ª–µ–¥—É—é—â–µ–π –ª–µ–∫—Ü–∏–∏).\n",
    "\n",
    "–•–æ—Ç—è —Å–µ–π—á–∞—Å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –¥–µ—Ä–∂–∞—Ç –ø–µ—Ä–≤–µ–Ω—Å—Ç–≤–æ –≤–æ –º–Ω–æ–≥–∏—Ö –æ–±–ª–∞—Å—Ç—è—Ö, –¥–ª—è –∏—Ö –æ–±—É—á–µ–Ω–∏—è –≤ —Å–∏–ª—É –∏—Ö —Ä–∞–∑–º–µ—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è:\n",
    "- –Ω–µ—Å–æ–∏–∑–º–µ—Ä–∏–º–æ –±–æ–ª—å—à–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö, –Ω–µ–∂–µ–ª–∏ –¥–ª—è RNN;\n",
    "- –±–æ–ª—å—à–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∫–∞–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫ –∏ –¥–ª—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–ª–æ–π –≤ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Ä–∞–±–æ—Ç—É —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:\n",
    "1. –ù–∞ –≤—Ö–æ–¥ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤ $\\large x = \\{x_1,...x_t,...,x_T\\}$, –≥–¥–µ $\\large x_t$ ‚Äî –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ —Å –∏–Ω–¥–µ–∫—Å–æ–º $t$.\n",
    "\n",
    "2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç—É–ø–∏–≤—à–µ–≥–æ $\\large x_t$ —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_t$, –∫–æ—Ç–æ—Ä–æ–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —è–≤–ª—è–µ—Ç—Å—è –ª–∏–Ω–µ–π–Ω—ã–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ–º –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è $\\large h_{t-1}$ –∏ —Ç–µ–∫—É—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $\\large x_t$, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏:\n",
    "$$\\large h_t = f_{\\text{act}}(W_{hh}h_{t-1} + W_{xh}x_t),$$\n",
    "–≥–¥–µ $\\large W_{hh}$ –∏ $\\large W_{xh}$  ‚Äî —ç—Ç–æ –º–∞—Ç—Ä–∏—Ü—ã –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–≤–µ—Å–∞). –¢–∞–∫–∂–µ –º–æ–∂–µ—Ç –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è –≤–µ–∫—Ç–æ—Ä —Å–º–µ—â–µ–Ω–∏–π (bias).\n",
    "\n",
    "–ö–æ–≥–¥–∞ –ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω $\\large x_0$ –ø–æ–¥–∞–µ—Ç—Å—è –≤ —è—á–µ–π–∫—É, —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_0$ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω—É–ª—è–º–∏.\n",
    "\n",
    "3. –ù–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—é—â–µ–≥–æ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è  $\\large x_t$, —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –≤—ã—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å $\\large y = \\{y_1,...y_t,...,y_T\\}$. –î–ª—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è $\\large y_t$ –≤ —Ç–µ–∫—É—â–∏–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤ –º–æ–¥–µ–ª—å –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –æ–±—ã—á–Ω—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –ø—Ä–∏–Ω–∏–º–∞—é—â–∏–π –Ω–∞ –≤—Ö–æ–¥ —Ç–µ–∫—É—â–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ $\\large h_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/rnn_basic_block.png\" width=\"1000\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "–í–µ–∫—Ç–æ—Ä $\\large y_t$ —è–≤–ª—è–µ—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ $\\large x_t$, –Ω–æ –∏ –≤–µ–∫—Ç–æ—Ä–æ–º –≤—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ç.–∫. —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–±–æ –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–∞—Ö. –í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ç–æ–ª—å–∫–æ –≤–µ–∫—Ç–æ—Ä –≤—Å–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–ª–æ–≤–∞)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN —Å–ª–æ–π –≤ PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í PyTorch –µ—Å—Ç—å —Å–ª–æ–π ‚Äî `torch.nn.RNN` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html), –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ª–æ–≥–∏–∫—É, –æ–ø–∏—Å–∞–Ω–Ω—É—é –≤—ã—à–µ.\n",
    "\n",
    "–¢–∞–∫–∂–µ –µ—Å—Ç—å —Å—É—â–Ω–æ—Å—Ç—å `torch.nn.RNNCell` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html), –∫–æ—Ç–æ—Ä–∞—è —Ä–µ–∞–ª–∏–∑—É–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º —Ç–∞–∫—Ç–µ –≤—Ä–µ–º–µ–Ω–∏.\n",
    "\n",
    "–°–ª–æ–π `nn.RNN` —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —è–≤–ª—è–µ—Ç—Å—è –æ–±–µ—Ä—Ç–∫–æ–π, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–∑—ã–≤–∞–µ—Ç `nn.RNNCell` –≤ —Ü–∏–∫–ª–µ –ø–æ –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–ª–æ—è `nn.RNN`:\n",
    "\n",
    "* **`input_size`** ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å $\\large x_t$, —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ.\n",
    "\n",
    "* **`hidden_size`** ‚Äî —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å $\\large h_t$, —Ü–µ–ª–æ–µ —á–∏—Å–ª–æ. –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤ –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–º —Å–ª–æ–µ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–ª–æ–µ–≤ –≤ PyTorch: –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–∂–∏–¥–∞–µ–º—ã–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Ö–æ–¥–∞ —Ç–∞–∫–∏–µ:\n",
    "\n",
    "**`[–¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞]`**\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ –µ—Å–ª–∏ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–ª–æ—è —É–∫–∞–∑–∞—Ç—å `batch_first=True`, —Ç–æ –º–æ–∂–Ω–æ –ø–æ–¥–∞–≤–∞—Ç—å –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –±–æ–ª–µ–µ –ø—Ä–∏–≤—ã—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –∫–æ–≥–¥–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ —Å—Ç–æ–∏—Ç –Ω–∞ –ø–µ—Ä–≤–æ–º –º–µ—Å—Ç–µ:\n",
    "\n",
    "**`[—Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞, –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞]`**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2, batch_first=True)\n",
    "\n",
    "dummy_batched_seq = torch.randn((16, 57, 3))  # batch_size, seq_len, input_size\n",
    "out, h = rnn(dummy_batched_seq)\n",
    "\n",
    "print(\"Input shape:\".ljust(20), f\"{dummy_batched_seq.shape}\")\n",
    "print(\"Out shape:\".ljust(20), f\"{out.shape}\")\n",
    "print(\"Last hidden state shape:\".ljust(20), f\"{h.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≤—ã–∑–æ–≤–µ —Å–ª–æ–π –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–≤–∞ –æ–±—ä–µ–∫—Ç–∞:\n",
    "* `out` ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π,\n",
    "* `h` ‚Äî —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Ç–∞–∫—Ç–µ.\n",
    "\n",
    "–ú—ã —É–∫–∞–∑–∞–ª–∏ `batch_first=True`, –ø—Ä–∏ —ç—Ç–æ–º `out` —Å–æ—Ö—Ä–∞–Ω–∏–ª –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π, –∫–∞–∫ —É –≤—Ö–æ–¥–∞, –∞ –≤–æ—Ç —É `h` —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞ –≤—Å—Ç–∞–ª–∞ –Ω–∞ –≤—Ç–æ—Ä–æ–µ –º–µ—Å—Ç–æ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_batch_first = h.permute(1, 0, 2)\n",
    "\n",
    "print(f\"h is last out: {(h_batch_first == out[:, -1:, :]).all().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN-–±–ª–æ–∫–∏ –º–æ–∂–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è—Ç—å –≤ —Å–ª–æ–∏, –Ω–∞–∫–ª–∞–¥—ã–≤–∞—è –∏—Ö –¥—Ä—É–≥ –Ω–∞ –¥—Ä—É–≥–∞. –î–ª—è —ç—Ç–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ `torch.nn.RNN` –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç `num_layers`, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–≥–æ –º–æ–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ—ë–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/rnn_multiple_layers.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((16, 6, 3))  # batch_size, seq_len, input_size\n",
    "rnn = torch.nn.RNN(input_size=3, hidden_size=2, num_layers=2, batch_first=True)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "print()\n",
    "print(\"Out:\\n\", out.shape)  # Hidden states for all elements from top layer\n",
    "print(\"h:\\n\", h.shape)  # Hidden states for last element for all layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Ç–µ–∫—Å—Ç–∞—Ö –Ω–∞—á–∞–ª–æ –∏–ª–∏ –æ–∫–æ–Ω—á–∞–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏–∑–º–µ–Ω–∏—Ç—å –µ–≥–æ —Å–º—ã—Å–ª. –¢–∞–∫, –≤ –∑–∞–¥–∞—á–∞—Ö –æ—Ü–µ–Ω–∫–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏, –º–æ–∂–Ω–æ –ª–µ–≥–∫–æ –æ—à–∏–±–∏—Ç—å—Å—è, –µ—Å–ª–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –æ–¥–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –∑–∞–±—ã–≤–∞—è –Ω–∞—á–∞–ª–æ.\n",
    "\n",
    "–î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —è–≤–ª—è–µ—Ç—Å—è –≤–∞–∂–Ω–µ–π—à–µ–π –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å—é, –∫–æ—Ç–æ—Ä—É—é –º—ã –±—É–¥–µ–º —É—á–∏—Ç—ã–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/movie_sentiment.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —á–µ—Ä–µ–∑ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—É—é —Å–µ—Ç—å –¥–≤–∞ —Ä–∞–∑–∞: –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ —Å–ª–æ–≤ –≤ –ø—Ä—è–º–æ–º –∏ –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏. –î–ª—è —ç—Ç–æ–≥–æ —Å–æ–∑–¥–∞—ë—Ç—Å—è –µ—â–µ –æ–¥–∏–Ω —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–π —Å–ª–æ–π, –∫–æ—Ç–æ—Ä—ã–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ –æ–±—Ä–∞—Ç–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏, –∞ —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–≤—É—Ö —Å–ª–æ—ë–≤ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ—Ç—Å—è.\n",
    "\n",
    "[[blog] ‚úèÔ∏è Recurrent Neural Networks with PyTorch](https://www.kaggle.com/code/kanncaa1/recurrent-neural-network-with-pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/bidirectional.png\" width=\"650\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é —Ç–∞–∫–æ–π –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–ª–æ—è—Ö –æ—Ç–≤–µ—á–∞–µ—Ç —Ñ–ª–∞–≥ `bidirectional=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn((16, 57, 3))  # batch_size, seq_len, input_size\n",
    "rnn = torch.nn.RNN(3, 2, bidirectional=True, batch_first=True)\n",
    "\n",
    "out, h = rnn(dummy_input)\n",
    "\n",
    "# Concatenated Hidden states from both layers\n",
    "print(\"Out:\\n\", out.shape)\n",
    "# Hidden states last element from  both : 2*num_layers*hidden_state\n",
    "print(\"h:\\n\", h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–±–ª–µ–º—ã RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —Å—Ä–∞–∑—É –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ —Å–µ—Ç—å –∏ –∑–∞—Ç–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç, –æ–¥–Ω–∞–∫–æ –≤–æ–∑–Ω–∏–∫–Ω—É—Ç —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:\n",
    "\n",
    " - –±–æ–ª—å—à–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ –ø–æ–º–µ—Å—Ç—è—Ç—Å—è –≤ –ø–∞–º—è—Ç–∏,\n",
    " - —Ç–∞–∫ –∫–∞–∫ —Ü–µ–ø–æ—á–∫–∞ –±—É–¥–µ—Ç –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–π, –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏–µ/–≤–∑—Ä—ã–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞,\n",
    " - –ø–æ –º–µ—Ä–µ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è —Å–∏–≥–Ω–∞–ª–∞ –ø–æ —Ü–µ–ø–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞—Ç–∏—Ä–∞–µ—Ç—Å—è.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–æ–ø—É—Å—Ç–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å –¥–ª–∏–Ω–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å. –ï—Å–ª–∏ –º—ã —Å—Ä–∞–∑—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º, —Ç–æ –≤ –∫–∞–∂–¥—ã–π –º–æ–º–µ–Ω—Ç –≤—Ä–µ–º–µ–Ω–∏ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–∏—Ç—å Loss. –ò –≤—Å–µ —è—á–µ–π–∫–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤–æ –≤—Ä–µ–º—è backpropogation. –í—Å–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω—É–∂–Ω–æ –ø–æ—Å—á–∏—Ç–∞—Ç—å. –í–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –Ω–µ—Ö–≤–∞—Ç–∫–æ–π –ø–∞–º—è—Ç–∏.\n",
    "\n",
    "–ï—Å—Ç—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–∞–∫–æ–π –¥–ª–∏–Ω—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RNN –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏. –ï—Å–ª–∏ –º—ã –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —è—á–µ–π–∫–µ, –º–æ–∂–µ—Ç –æ–∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, —Å–∫–∞–∂–µ–º, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 10 —Å–ª–æ–≤–∞—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ Tanh –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –∑–∞—Ç–∏—Ä–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/backprop_through_time.png\" width=\"700\"><center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"http://cs231n.stanford.edu/slides/2021/lecture_10.pdf\">CS231n: Recurrent Neural Network</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ç—É—Ö–∞—é—â–∏–π/–≤–∑—Ä—ã–≤–∞—é—â–∏–π—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç (Vanishing/exploding gradient) ‚Äî —è–≤–ª–µ–Ω–∏—è –∑–∞—Ç—É—Ö–∞—é—â–µ–≥–æ –∏ –≤–∑—Ä—ã–≤–∞—é—â–µ–≥–æ—Å—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ RNN. –ò –ø—Ä–∏ –±–æ–ª—å—à–æ–π –¥–ª–∏–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –∫—Ä–∏—Ç–∏—á–Ω—ã–º. –ü—Ä–∏—á–∏–Ω–∞ –≤ —Ç–æ–º, —á—Ç–æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –≤–µ–ª–∏—á–∏–Ω—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞ –æ—Ç —á–∏—Å–ª–∞ —Å–ª–æ—ë–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è, –ø–æ—Å–∫–æ–ª—å–∫—É –≤–µ—Å–∞ —É–º–Ω–æ–∂–∞—é—Ç—Å—è –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ.\n",
    "\n",
    "$dL ‚àù (W)^N:$\n",
    "\n",
    "$W > 1 \\rightarrow$ –≤–∑—Ä—ã–≤, $W < 1 \\rightarrow$ –∑–∞—Ç—É—Ö–∞–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/simple_rnn_backprop.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—ã—á–Ω–∞—è RNN –∏–º–µ–ª–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–æ–±–ª–µ–º, –≤ —Ç–æ–º —á–∏—Å–ª–µ –≤ –Ω–µ–π –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ –∑–∞—Ç—É—Ö–∞–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ü–æ–º–∏–º–æ —ç—Ç–æ–≥–æ –±—ã–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –∑–∞—Ç—É—Ö–∞–Ω–∏–µ–º/–≤–∑—Ä—ã–≤–æ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞.\n",
    "\n",
    "–≠—Ç–∏ –ø—Ä–æ–±–ª–µ–º—ã –±—ã–ª–∏ —á–∞—Å—Ç–∏—á–Ω–æ —Ä–µ—à–µ–Ω—ã –≤ LSTM, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω–æ–π –≤ —Å—Ç–∞—Ç—å–µ:\n",
    "\n",
    "[[article]üéìHochreiter S., Schmidhuber J. (1997). Long Short-Term Memory](http://www.bioinf.jku.at/publications/older/2604.pdf).\n",
    "\n",
    "–í –æ–±—ã—á–Ω–æ–π RNN-—è—á–µ–π–∫–µ –±—ã–ª —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—É—Ç—å –ø–µ—Ä–µ–¥–∞—á–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –º—ã –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å —Ç–µ–∫—É—â–∏–º –≤—Ö–æ–¥–æ–º –∏ –ø—Ä–æ–ø—É—Å–∫–∞–ª–∏ –∏—Ö —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src = \"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/simple_rnn_h_state.png\" width=\"500\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = \\tanh(W \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ —ç—Ç–æ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ—á–µ–Ω—å –±—ã—Å—Ç—Ä–æ –∑–∞—Ç—É—Ö–∞–µ—Ç –∏ —Ç–µ—Ä—è–µ—Ç—Å—è –æ–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏.\n",
    "\n",
    "–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —è—á–µ–π–∫–∏ LSTM –Ω–∞–º–Ω–æ–≥–æ —Å–ª–æ–∂–Ω–µ–µ. –ó–¥–µ—Å—å –µ—Å—Ç—å —Ü–µ–ª—ã—Ö 4 –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞–∑–Ω—ã–µ –∑–∞–¥–∞—á–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/lstm_chain.png\" width=\"500\"></center>\n",
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/lstm_chain_notation.png\" width=\"700\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large f_t = œÉ(W_f \\cdot [h_{t-1}, x_t])\\ \\ \\ \\ $\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{forget  gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large i_t = œÉ(W_i \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{input gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large o_t = œÉ(W_o \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{output gate}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large c^\\prime_t = \\tanh(W_c \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{candidate cell state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large c_t = f_t\\otimes c_{t-1} + i_t \\otimes c^\\prime_t$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large \\text{cell state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = o_t\\otimes \\tanh(c_t)$\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "$$\\large  \\text{hidden state}$$\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–ª–∞–≤–Ω–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ: –≤ LSTM –¥–æ–±–∞–≤–ª–µ–Ω –ø—É—Ç—å $c$, –∫–æ—Ç–æ—Ä—ã–π –ø–æ –∑–∞–¥—É–º–∫–µ –¥–æ–ª–∂–µ–Ω —ç—Ç–æ—Ç –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/lstm_c_state_highway.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –ø—É—Ç—å $c$ (cell state, –∏–Ω–æ–≥–¥–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è highway, –º–∞–≥–∏—Å—Ç—Ä–∞–ª—å)  –ø–æ–º–æ–≥–∞–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –≤—Å—Ç—Ä–µ—Ç–∏–≤—à—É—é—Å—è –≤ –∫–∞–∫–æ–π-—Ç–æ –º–æ–º–µ–Ω—Ç –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—à–ª–æ–º, –≤—Å–µ –≤—Ä–µ–º—è, –ø–æ–∫–∞ —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Ç—Ä–µ–±—É–µ—Ç—Å—è.\n",
    "\n",
    "–ü–æ —Ñ–æ—Ä–º—É–ª–∞–º —Ç–∞–∫–∂–µ –≤–∏–¥–Ω–æ, –∫–∞–∫ –≤–æ–∑—Ä–æ—Å–ª–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–ª–∏—á–∏–µ –æ—Ç RNN —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –∫—Ä–æ–º–µ $h$ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç—Å—è –µ—â–µ –∏ $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "lstm = nn.LSTM(input_size=3, hidden_size=2, batch_first=True)\n",
    "input = torch.randn(16, 57, 3)  # batch_size, seq_len, input_size\n",
    "out, (h, c) = lstm(input)  # h and c returned in tuple\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h\".ljust(15), h.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Shape of c\".ljust(15), c.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Output shape:\".ljust(15), out.shape)  # batch_size, seq_len, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º–∞—è –∏–∑–≤–µ—Å—Ç–Ω–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è LSTM ‚Äî GRU. –û–Ω–∞ –±–æ–ª–µ–µ –∫–æ–º–ø–∞–∫—Ç–Ω–∞ –∑–∞ —Å—á–µ—Ç —Å–∏–ª—å–Ω—ã—Ö —É–ø—Ä–æ—â–µ–Ω–∏–π –≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ —Å–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π LSTM.\n",
    "\n",
    "–ì–ª–∞–≤–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è: –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã forget –∏ input gates, —Å–ª–∏—Ç—ã $h_t$ –∏ $c_t$, –∫–æ—Ç–æ—Ä—ã–µ –≤ –æ–±—ã—á–Ω–æ–π LSTM —Ç–æ–ª—å–∫–æ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –¥—Ä—É–≥ –¥—Ä—É–≥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table, th, td {\n",
    "  border: 1px solid black;\n",
    "  border-collapse: collapse;\n",
    "}\n",
    "<font size=\"2\" face=\"Times New Romans\" >\n",
    "\n",
    "\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/gru_basic_block.png\" width=\"500\"></center>\n",
    "\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<table >\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large z_t = \\sigma(W_z \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large r_t = \\sigma(W_r \\cdot [h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large \\tilde h_t = \\tanh(W \\cdot [r_t \\otimes h_{t-1}, x_t])$\n",
    "\n",
    "</td>\n",
    "\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>\n",
    "\n",
    "$\\large h_t = (1-z_t) \\otimes h_{t-1} + z_t \\otimes \\tilde h_t$\n",
    "\n",
    "</td>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = nn.GRU(input_size=3, hidden_size=2, batch_first=True)\n",
    "input = torch.randn(16, 57, 3)  # batch_size, seq_len, input_size\n",
    "out, h = gru(input)\n",
    "\n",
    "print(\"Input shape:\".ljust(15), input.shape)\n",
    "print(\"Shape of h:\".ljust(15), h.shape)  # 1, batch_size, hidden_size\n",
    "print(\"Output shape:\".ljust(15), out.shape)  # batch_size, seq_len, hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ–ø—ã—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π: –∏–Ω–æ–≥–¥–∞ –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç GRU, –∏–Ω–æ–≥–¥–∞ ‚Äî LSTM. –¢–æ—á–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç —É—Å–ø–µ—Ö–∞ —Å–∫–∞–∑–∞—Ç—å –Ω–µ–ª—å–∑—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–∏–ø—ã –∑–∞–¥–∞—á"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–Ω–æ–π.\n",
    "\n",
    "–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç ‚Äî **¬´–æne to one¬ª** (–æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –Ω–∞ –≤—Ö–æ–¥–µ, –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤—ã—Ö–æ–¥–µ). –ù–∞–ø—Ä–∏–º–µ—Ä, **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π**: –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞–µ—Ç—Å—è –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç, –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞. –î–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ –ø–æ–¥–æ–π–¥–µ—Ç **–æ–±—ã—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å**, –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø—Ä–∏–º–µ–Ω—è—Ç—å RNN –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º —Å–ª—É—á–∞–∏, –≥–¥–µ –æ–ø—Ä–∞–≤–¥–∞–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **—Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–æ–π —Å–µ—Ç–∏** –æ–ø—Ä–∞–≤–¥–∞–Ω–æ:\n",
    "\n",
    "1. –ë–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî **¬´one to many¬ª** (–æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç –Ω–∞ –≤—Ö–æ–¥–µ, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤—ã—Ö–æ–¥–æ–≤). –¢–∞–∫–æ–π —Ç–∏–ø –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∞–∫—Ç—É–∞–ª–µ–Ω, –∫–æ–≥–¥–∞ –º—ã –≥–æ–≤–æ—Ä–∏–º –æ **–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏**: –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–∫—Å—Ç–æ–≤ –∏–ª–∏ –º—É–∑—ã–∫–∏.\n",
    "- –∑–∞–¥–∞–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ –∏–ª–∏ –Ω–∞—á–∞–ª—å–Ω—ã–π –∑–≤—É–∫;\n",
    "- –º–æ–¥–µ–ª—å –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—ã—Ö–æ–¥—ã;\n",
    "- –≤—Ö–æ–¥ –∫ –æ—á–µ—Ä–µ–¥–Ω–æ–π —è—á–µ–π–∫–µ ‚Äî —ç—Ç–æ –≤—ã—Ö–æ–¥ —Å –ø—Ä–æ—à–ª–æ–π —è—á–µ–π–∫–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏.\n",
    "2. –ó–∞–¥–∞—á–∞ **many-to-one** (–Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ, –æ–¥–∏–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤—ã—Ö–æ–¥–µ). –†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω–∞—è —Å–µ—Ç—å –≤—ã–¥–∞–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ, –æ–¥–Ω–∞–∫–æ –≤ —ç—Ç–æ–º —Å–ª—É—á–∞–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç, –≤—ã–¥–∞–Ω–Ω—ã–π –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–º —à–∞–≥–µ. –≠—Ç–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ –¥–ª—è **–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**: –º—ã –¥–æ–ª–∂–Ω—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤—Ö–æ–¥—ã –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∏ —Ç–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ü–µ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å—Å—è —Å –∫–ª–∞—Å—Å–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/one_or_many_to_one_or_many_ways_1.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑–º–æ–∂–Ω–∞ –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏ **¬´many to many¬ª** (–Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –≤—Ö–æ–¥–µ, –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ) –≤–æ–∑–º–æ–∂–Ω–∞ –≤ –¥–≤—É—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö:\n",
    "\n",
    "1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ **–≤—ã—Ö–æ–¥–æ–≤** –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ **–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ —Ä–∞–≤–Ω–æ** –∫–æ–ª–∏—á–µ—Å—Ç–≤—É **–≤—Ö–æ–¥–æ–≤**. –≠—Ç–æ –∞–∫—Ç—É–∞–ª—å–Ω–æ –≤ **–º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ**, –∫–æ–≥–¥–∞ –æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ —Ñ—Ä–∞–∑–∞ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å **—Ä–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤** –≤ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö.\n",
    "\n",
    "2. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ **–≤—ã—Ö–æ–¥–æ–≤** –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ **—Ä–∞–≤–Ω–æ** –∫–æ–ª–∏—á–µ—Å—Ç–≤—É **–≤—Ö–æ–¥–æ–≤**. –û–±—ã—á–Ω–æ —ç—Ç–æ –∑–∞–¥–∞—á–∏ **—Ä–∞–∑–º–µ—Ç–∫–∏** –∏—Å—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –ù–∞–ø—Ä–∏–º–µ—Ä, —É–∫–∞–∑–∞—Ç—å —Å—Ç–æ–ª–∏—Ü—ã –≥–æ—Ä–æ–¥–æ–≤, –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞–∂–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤, –≤–µ—â–µ—Å—Ç–≤ –∏ —Ç.–¥., —á—Ç–æ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∑–∞–¥–∞—á–∞–º –≤–∏–¥–∞ NER (Named entity recogition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/one_or_many_to_one_or_many_ways_2.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ ‚Äî –≤–∞–∂–Ω–µ–π—à–∞—è —á–∞—Å—Ç—å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ NLP. –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –≤–æ –≤—Å–µ—Ö –∑–∞–¥–∞—á–∞—Ö, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π —Ç–µ–∫—Å—Ç–∞, –Ω–∞–ø—Ä—è–º—É—é –∏–ª–∏ –∫–æ—Å–≤–µ–Ω–Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏. –ê –Ω–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –Ω–µ–¥–∞–≤–Ω–∏–µ –ø—Ä–æ—Ä—ã–≤—ã –≤ –æ–±–ª–∞—Å—Ç–∏ ‚Äî —ç—Ç–æ –ø–æ –±–æ–ª—å—à–µ–π —á–∞—Å—Ç–∏ –Ω–æ–≤—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ —è–∑—ã–∫–æ–≤–æ–º—É –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—é. ELMO, BERT, GPT ‚Äî —ç—Ç–æ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ó–∞–¥–∞—á–∞ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ $S$  ‚Äî –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–ª–æ–≤ $(w_1,\\cdots ,w_n)$. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–≤:\n",
    "$$P(w_1,w_2, \\dots, w_n) = p(w_1)p(w_2|w_1)p(w_3|w_1,w_2)\\dots p(w_n|w_1,w_2,\\dots,w_{n-1})= \\prod\\limits_{i = 1}^n p(w_i|w_1, \\dots, w_{i-1})$$\n",
    "–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—Å—Ç—Ä–µ—Ç–∏—Ç—å –µ–≥–æ –≤ —Ç–µ–∫—Å—Ç–µ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏, —á—Ç–æ –∏–∑–≤–µ—Å—Ç–Ω–æ –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–ª–æ–≤–æ: $w_2$ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ $w_1$, $w_3$ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ $w_1$ –∏ $w_2$, –∏ —Ç.–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/sentence.png\" width=\"700\"><center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://thegradient.pub/understanding-evaluation-metrics-for-language-models/\">Evaluation Metrics for Language Modeling</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å—Ç–∏–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã ‚Üí –º–æ–∂–Ω–æ –æ–±—É—á–∏—Ç—å —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –æ—Ü–µ–Ω–∏–≤–∞—Ç—å —ç—Ç–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —á–∞—Å—Ç–æ—Ç—ã –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏ —Å–ª–æ–≤ –≤ –∫–æ—Ä–ø—É—Å–µ —Ç–µ–∫—Å—Ç–æ–≤:\n",
    "$$p (w_i|w_{i-(n-1)}, \\dots, w_{i-1}) = \\frac{count(w_{i-(n-1)}, \\dots, w_{i-1}, w_{i})}{count(w_{i-(n-1)} \\dots, w_{i-1})}$$\n",
    "–¢–∞–∫–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è *n-–≥—Ä–∞–º–º–Ω—ã–º–∏*. –¢–µ—Ä–º–∏–Ω—ã *–±–∏–≥—Ä–∞–º–º–Ω—ã–µ* –∏ *—Ç—Ä–∏–≥—Ä–∞–º–º–Ω—ã–µ* —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –æ–±–æ–∑–Ω–∞—á–∞—é—Ç n-–≥—Ä–∞–º–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å $n = 2$ –∏ $n = 3$ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ.\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç: —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–ø–æ—Å–æ–±–Ω–∞ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–í—ã –Ω–∞–≤–µ—Ä–Ω—è–∫–∞ —Å—Ç–∞–ª–∫–∏–≤–∞–ª–∏—Å—å  –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏, –∫–æ–≥–¥–∞ –ø—Ä–∏ –≤–≤–æ–¥–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –≤–∞–º –ø—Ä–µ–¥–ª–∞–≥–∞–ª–∏—Å—å –≤–∞—Ä–∏–∞–Ω—Ç—ã –µ–≥–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "       \n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/keyboard.png\" width=\"400\"><center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/companies/ods/articles/716918/\">–≠–≤–æ–ª—é—Ü–∏—è —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å T9 –¥–æ —á—É–¥–∞</a></em></center>\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/search.png\" width=\"700\"><center>\n",
    "<em>–ò—Å—Ç–æ—á–Ω–∏–∫: –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤ Google</em>\n",
    "\n",
    "\n",
    "</td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Å–ø–æ—Å–æ–±–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞, —Ç–æ –æ–Ω–∞ —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–Ω–æ–≥–æ –∑–Ω–∞–µ—Ç –æ —è–∑—ã–∫–µ.\n",
    "\n",
    "*–Ø –ª—é–±–ª—é –≤–∫—É—Å–Ω—É—é ...*\n",
    "\n",
    "–ù–∞ –º–µ—Å—Ç–µ –ø—Ä–æ–ø—É—Å–∫–∞ –¥–æ–ª–∂–Ω–æ —Å—Ç–æ—è—Ç—å –Ω–µ–æ–¥—É—à–µ–≤–ª–µ–Ω–Ω–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∂–µ–Ω—Å–∫–æ–≥–æ —Ä–æ–¥–∞ –≤ –≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–º –ø–∞–¥–µ–∂–µ, –∫–æ—Ç–æ—Ä–æ–µ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç –Ω–µ—á–Ω–æ —Å—ä–µ–¥–±–Ω–æ–µ (*–µ–¥—É, –∫–æ–ª–±–∞—Å—É, —Ä—ã–±—É* –∏ —Ç.–¥.).\n",
    "\n",
    "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: –µ—Å–ª–∏ –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ —Å–ª–æ–≤–æ $w_1$, —Ç–æ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∂–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ $w_2$. –ó–∞—Ç–µ–º —Å–ª–æ–≤–∞ $w_1$ –∏ $w_2$ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ $w_3$.\n",
    "\n",
    "–û—Å–Ω–æ–≤–Ω–æ–π –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ —Å—á–µ—Ç–Ω—ã—Ö (*n*-–≥—Ä–∞–º–º–Ω—ã—Ö) —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∏ –Ω–µ —Å–ø–æ—Å–æ–±–Ω—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç.\n",
    "\n",
    "–° —ç—Ç–∏–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏ —Å–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–µ—Ç–µ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –¥–æ–ª–∂–Ω—ã —Ö–æ—Ä–æ—à–æ –ø–æ–¥—Ö–æ–¥–∏—Ç—å –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–∏ –ø—Ä–æ—Ö–æ–¥—è—Ç –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∑–∞–ø–æ–º–∏–Ω–∞—é—Ç –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É RNN –¥–ª—è –∑–∞–¥–∞—á–∏ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è.\n",
    "\n",
    "–®–∞–≥ 1. Embedding\n",
    "\n",
    "–ï—Å—Ç—å –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏–∑ $n$ —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ú—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–µ —á–µ—Ä–µ–∑ —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, –∫–æ—Ç–æ—Ä—ã–π –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/LSTM_lm_1.png\" width=\"700\"><center>\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782\">Investigation on N-gram Approximated RNNLMs for Recognition of Morphologically Rich Speech</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–®–∞–≥ 2. LSTM1, LSTM2\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ —è—á–µ–π–∫–∏ LSTM –ø–æ—Å—Ç—É–ø–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã. –°–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å, hidden state) —ç–ª–µ–º–µ–Ω—Ç–∞ $w_i$ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —è—á–µ–π–∫—É —Ç–æ–≥–æ –∂–µ —Å–ª–æ—è –≤–º–µ—Å—Ç–µ —Å —ç–ª–µ–º–µ–Ω—Ç–æ–º $w_{i+1}$. –ù–∞ —Ä–∏—Å—É–Ω–∫–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ 2 —Å–ª–æ—è LSTM. –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ $w_i$ –Ω–∞ —Å–ª–æ–µ LSTM1 –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —Ç–∞–∫–∂–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Å–ª–æ–π LSTM2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/LSTM_lm_2.png\" width=\"700\"><center>\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782\">Investigation on N-gram Approximated RNNLMs for Recognition of Morphologically Rich Speech</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–®–∞–≥ 3. Softmax\n",
    "\n",
    "–í—ã—Ö–æ–¥ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è ‚Äî –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –û–¥–Ω–∞–∫–æ –≤ –∑–∞–¥–∞—á–µ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –º—ã –¥–æ–ª–∂–Ω—ã –ø–æ–ª—É—á–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ  –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ —Ç–µ–∫—É—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–µ–∫—Ç–æ—Ä –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ —Ä–∞–≤–Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —Å–ª–æ–≤–∞—Ä–µ. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ softmax.\n",
    "\n",
    "–î–ª—è —ç–ª–µ–º–µ–Ω—Ç–∞ $w_i$ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–∞ $w_{i+1}$ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ $w_1, \\cdots, w_i$ (–ø–æ –ø—Ä–æ—à–ª–æ–º—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –±—É–¥—É—â–µ–µ)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/LSTM_lm_3.png\" width=\"700\"><center>\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782\">Investigation on N-gram Approximated RNNLMs for Recognition of Morphologically Rich Speech</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∏ –ø–æ—Å—á–∏—Ç–∞—Ç—å —Ä–∞–∑–º–µ—Ä –æ—à–∏–±–∫–∏. –í –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ, –Ω–æ —Å–¥–≤–∏–Ω—É—Ç—ã–µ –Ω–∞ 1 —à–∞–≥. –≠—Ç–æ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç—Å—è –∑–∞ —Å—á–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –Ω–∞—á–∞–ª–∞ START –∏ –∫–æ–Ω—Ü–∞ END –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–î–ª—è —ç–ª–µ–º–µ–Ω—Ç–∞ START –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º –±—É–¥–µ—Ç —ç–ª–µ–º–µ–Ω—Ç h, –¥–ª—è h ‚Äî e, –¥–ª—è e ‚Äî l, –∏ —Ç.–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/rnn_generation.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.researchgate.net/figure/The-recurrent-LSTM-language-model-structure-used-in-our-experiments_fig1_336086782\">Building Char-RNN</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –æ–Ω–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –Ω—É–∂–Ω—ã —Ç–æ–ª—å–∫–æ —Å—ã—Ä—ã–µ —Ç–µ–∫—Å—Ç—ã, –Ω–∞ –Ω–∏—Ö –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–ö–∞–∫ —Ç–æ–ª—å–∫–æ —É –Ω–∞—Å –±—É–¥–µ—Ç —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, –º—ã —Å–º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–µ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞. –ú—ã –¥–µ–ª–∞–µ–º —ç—Ç–æ –ø–æ –æ–¥–Ω–æ–º—É —Ç–æ–∫–µ–Ω—É –∑–∞ —Ä–∞–∑: –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ–ª–∞–µ–º –≤—ã–±–æ—Ä–∫—É (sampling) –∏–∑ —ç—Ç–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "       \n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_1.png\" width=\"400\"></center>\n",
    "<em>1</em>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_2.png\" width=\"400\"></center>\n",
    "<em>2</em>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_3.png\" width=\"400\"></center>\n",
    "<em>3</em>\n",
    "</td>\n",
    "     </tr>\n",
    "     \n",
    "<div align=\"center\">\n",
    "    <table >\n",
    "  <tr>\n",
    "     <td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_4.png\" width=\"400\"></center>\n",
    "<em>4</em>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_5.png\" width=\"400\"></center>\n",
    "<em>5</em>\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/generation_6.png\" width=\"400\"></center>\n",
    "<em>6</em>\n",
    "</td>\n",
    "     </tr>\n",
    "    </table >\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/language_modeling.html#n_gram_generation\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ (greedy decoding): –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Ç–æ–∫–µ–Ω —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é. –û–¥–Ω–∞–∫–æ –æ–±—ã—á–Ω–æ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ—Å–∏–º–≤–æ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –æ–±—É—á–∏–º —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–∏–º–≤–æ–ª–æ–≤.\n",
    "\n",
    "–í –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [[doc] üõ†Ô∏è –∫–æ—Ä–ø—É—Å –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∏–Ω–æ–∑–∞–≤—Ä–æ–≤](https://www.kaggle.com/datasets/swimmingwhale/dinosaur-island).\n",
    "\n",
    "–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è —ç—Ç–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç —Å–ø–æ—Å–æ–±–Ω–∞ –ø–æ—Ä–æ–∂–¥–∞—Ç—å –Ω–æ–≤—ã–µ –∏–º–µ–Ω–∞ –¥–∏–Ω–æ–∑–∞–≤—Ä–æ–≤, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã—Ö –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ñ–∞–π–ª–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/datasets/dinos.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 dinos names:\\n\")\n",
    "!head dinos.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Last 10 dinos names:\\n\")\n",
    "!tail dinos.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –¥–æ—Å—Ç—É–ø–Ω—É—é —Å—Ä–µ–¥—É –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –∫–ª–∞—Å—Å `DinoDataset`, –Ω–∞—Å–ª–µ–¥–Ω–∏–∫ –∫–ª–∞—Å—Å–∞ `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DinosDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    with open('dinos.txt') as f:\n",
    "      content = f.read().lower()\n",
    "      self.vocab = sorted(set(content)) + ['<','>'] # –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ª–æ–≤–∞—Ä—å –≤—Å–µ –±—É–∫–≤—ã, –∞ —Ç–∞–∫–∂–µ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã –Ω–∞—á–∞–ª–∞ –∏ –∫–æ–Ω—Ü–∞\n",
    "      self.vocab_size = len(self.vocab) # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è\n",
    "      self.lines = content.splitlines() # —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º\n",
    "    self.char2id = {char:id for id,char in enumerate(self.vocab)} # —Å–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å, –∫–∞–∂–¥–æ–º—É —Å–∏–º–≤–æ–ª—É –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å\n",
    "    self.id2char = {id:char for id,char in enumerate(self.vocab)}\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    line = self.lines[index]\n",
    "    \"\"\"\n",
    "    Input data x_str: special symbol for beginning of the sequence + sequence\n",
    "    Output data y_str: sequence + special symbol for end of the sequence\n",
    "    \"\"\"\n",
    "    x_str = '<' + line\n",
    "    y_str = line + '>'\n",
    "    x = torch.empty(len(x_str), dtype=torch.long, device=device) # —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    y = torch.empty(len(y_str), dtype=torch.long, device=device) # —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Ç–µ–Ω–∑–æ—Ä –¥–ª—è –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)): # –ø–µ—Ä–µ–≤–æ–¥–∏–º —Å–∏–º–≤–æ–ª—ã –≤ –∏–Ω–¥–µ–∫—Å—ã –ø–æ —Å–ª–æ–≤–∞—Ä—é char2id\n",
    "      x[i] = self.char2id[x_ch]\n",
    "      y[i] = self.char2id[y_ch]\n",
    "    return x,y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.lines) # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dinos_dataset = DinosDataset()\n",
    "dinos_dataloader = DataLoader(dinos_dataset, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –≤—Ö–æ–¥–Ω—ã–µ –∏ –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è —Å–¥–≤–∏–≥–æ–º –Ω–∞ –æ–¥–∏–Ω —à–∞–≥."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dinos_dataloader))\n",
    "print(f\"Shape of input sequence: {x.shape}\")\n",
    "print(f\"Input sequence (indexes):\\n{x}\")\n",
    "print(f\"Input sequence (symbols):\\n{[dinos_dataset.id2char[int(i)] for i in x[0]]}\\n\")\n",
    "print(f\"Shape of output sequence: {y.shape}\")\n",
    "print(f\"Output sequence (indexes):\\n{y}\")\n",
    "print(f\"Output sequence (symbols):\\n{[dinos_dataset.id2char[int(i)] for i in y[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of unique symbols: {len(dinos_dataset.lines)}\")\n",
    "print(f\"Length of dataset: {dinos_dataset.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–π–¥–µ–º –∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é –º–æ–¥–µ–ª–∏. –û–Ω–∞ –≤–∫–ª—é—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–ª–æ–π, –¥–≤–∞ —Å–ª–æ—è LSTM –∏ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class LM(nn.Module):\n",
    "  def __init__(self, vocab_size):\n",
    "    super(LM, self).__init__()\n",
    "    self.lstm_size = 15 # —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π h –∏ c (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–∞—è –∏ –¥–æ–ª–≥–∞—è –ø–∞–º—è—Ç—å)\n",
    "    self.embedding_dim = 10 # —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–¥–ª–∏–Ω–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)\n",
    "    self.num_layers = 2 # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ LSTM\n",
    "\n",
    "    # —Å–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "    self.embedding = nn.Embedding(\n",
    "        num_embeddings=vocab_size,\n",
    "        embedding_dim=self.embedding_dim\n",
    "        )\n",
    "    # —Å–ª–æ–π LSTM\n",
    "    self.lstm = nn.LSTM(\n",
    "        input_size=self.embedding_dim,\n",
    "        hidden_size=self.lstm_size,\n",
    "        num_layers=self.num_layers\n",
    "    )\n",
    "    # –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π\n",
    "    self.hid2out = nn.Linear(\n",
    "        in_features=self.lstm_size,\n",
    "        out_features=vocab_size\n",
    "        )\n",
    "\n",
    "  def forward(self, x, prev_state=None):\n",
    "    embedding = self.embedding(x)\n",
    "    if prev_state:\n",
    "      output, state = self.lstm(embedding)\n",
    "    else:\n",
    "      output, state = self.lstm(embedding, prev_state)\n",
    "    logits = self.hid2out(output)\n",
    "\n",
    "    return logits, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LM(len(dinos_dataset.char2id)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ–Ω–∏–º –º–æ–¥–µ–ª—å –∫ –æ–¥–Ω–æ–º—É –±–∞—Ç—á—É –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º —Ä–∞–∑–º–µ—Ä –ø–æ–ª—É—á–∏–≤—à–∏—Ö—Å—è –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, (state_h, state_c) = model(x)\n",
    "print(f\"Shape of prediction: {y_pred.shape}\")\n",
    "print(f\"Shape of hidden state: {state_h.shape}\")\n",
    "print(f\"Shape of cell state: {state_c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –º–∞—Å—Å–∏–≤–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–µ—Ç–æ–¥ `np.random.choice` –≤—ã–±–∏—Ä–∞–µ—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º. –ï—Å–ª–∏ –º—ã –Ω–µ –∑–∞–¥–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, —Ç–æ –∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –±—É–¥–µ—Ç –≤—ã–±—Ä–∞–Ω –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"Sampling in range from 1 to 3:\")\n",
    "for i in range(10):\n",
    "  print(np.random.choice([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –º–æ–∂–µ—Ç –±—ã—Ç—å –∑–∞–¥–∞–Ω–æ —ç–∫—Å–ø–ª–∏—Ü–∏—Ç–Ω–æ. –ï—Å–ª–∏ —ç—Ç–æ ohe-hot –≤–µ–∫—Ç–æ—Ä, —Ç–æ –≤—Å–µ–≥–¥–∞ –±—É–¥–µ—Ç –≤—ã–±–∏—Ä–∞—Ç—å—Å—è –Ω–æ–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–π —Å—Ç–æ–∏—Ç 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = torch.nn.functional.one_hot(torch.tensor(2), len(dinos_dataset.char2id))\n",
    "print(f\"One-hot vector p1:\\n{p1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling with one-hot vector p1:\")\n",
    "\n",
    "for i in range(10):\n",
    "  pred_id = np.random.choice(np.arange(len(dinos_dataset.char2id)), p=p1)\n",
    "  print(pred_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –∫–æ—Ç–æ—Ä–æ–µ –±—ã–ª–æ –ø–æ–ª—É—á–µ–Ω–æ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å–µ—Ç–∏. –î–ª—è —ç—Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫ –≤—ã—Ö–æ–¥–Ω—ã–º –¥–∞–Ω–Ω—ã–º –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = y_pred[:, -1, :].unsqueeze(1)\n",
    "print(f\"Shape of logits: {logits.shape}\")\n",
    "print(f\"Logits:\\n{logits}\\n\")\n",
    "y_softmax_scores = torch.softmax(logits, dim=2)\n",
    "print(f\"Shape of predictions after softmax: {y_softmax_scores.shape}\")\n",
    "print(f\"Predictions after softmax:\\n{y_softmax_scores}\")\n",
    "print(f\"Sum of presictions: {torch.sum(y_softmax_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = y_softmax_scores.detach().cpu().numpy().ravel()\n",
    "print(f\"Numpy array of predictions after softmax p2:\\n{p2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sampling with predictions after softmax p2:\")\n",
    "for i in range(20):\n",
    "  pred_id = np.random.choice(np.arange(len(dinos_dataset.char2id)), p=p2)\n",
    "  print(pred_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ì–µ–Ω–µ—Ä–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏–π –¥–∏–Ω–æ–∑–∞–≤—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(dataset, model):\n",
    "  model.eval() # –ø–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "  newline_id = dataset.char2id['>'] # –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å —Å–∏–º–≤–æ–ª–∞ –∫–æ–Ω—Ü–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "  word_size = 0 # –±—É–¥–µ–º –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –¥–ª–∏–Ω—É –ø–æ—Ä–æ–∂–¥–∞–µ–º–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "  with torch.no_grad():\n",
    "    state_h, state_c = (None, None) # —Å–∫—Ä—ã—Ç—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –≤—Ä—É—á–Ω—É—é, –ø–æ—ç—Ç–æ–º—É –∏—Ö –Ω–∞–¥–æ —Ö—Ä–∞–Ω–∏—Ç—å\n",
    "    start_id = dataset.char2id['<'] # –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Å–∏–º–≤–æ–ª–∞ –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    indices = [start_id] # —Å–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫, –≥–¥–µ –±—É–¥–µ–º —Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è\n",
    "    word_size += 1 # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "    pred_id = start_id # –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–∏–º–≤–æ–ª –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∫ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "    x = torch.tensor([[pred_id]]).to(device) # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä\n",
    "\n",
    "    \"\"\"\n",
    "    –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–≤–∞ —É—Å–ª–æ–≤–∏—è –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Ü–∏–∫–ª–µ while:\n",
    "    1) —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Å–∏–º–≤–æ–ª–æ–º –∫–æ–Ω—Ü–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ '>'\n",
    "    –∏\n",
    "    2) –¥–ª–∏–Ω–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ–Ω—å—à–µ 20\n",
    "    \"\"\"\n",
    "    while pred_id != newline_id and word_size < 20:\n",
    "      logits, (state_h, state_c) = model(x, (state_h, state_c)) # –ø–µ—Ä–µ–¥–∞–µ–º –≤ –º–æ–¥–µ–ª—å —Ç–µ–Ω–∑–æ—Ä —Å —Ç–µ–∫—É—â–∏–º —Å–∏–º–≤–æ–ª–æ–º x, –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è h –∏ c\n",
    "      y_softmax_scores = torch.softmax(logits, dim=2) # –ø—Ä–∏–º–µ–Ω—è–µ–º softmax –∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º –º–æ–¥–µ–ª–∏\n",
    "      pred_id = np.random.choice( # –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∑–Ω–∞—á–µ–Ω–∏–π –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –º–∞—Å—Å–∏–≤–∞\n",
    "          np.arange(len(dinos_dataset.char2id)), # —Å –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –ø–æ–ª—É—á–∏–º –æ–¥–∏–Ω –∏–∑ 29 –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "          p=y_softmax_scores.detach().cpu().numpy().ravel() # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "          )\n",
    "      indices.append(pred_id) # –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π\n",
    "      x = torch.tensor([[pred_id]]).to(device) # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä\n",
    "      word_size += 1 # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "\n",
    "      if word_size == 20 and indices[-1] != newline_id:\n",
    "        indices.append(newline_id)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    return ''.join([dinos_dataset.id2char[i] for i in indices]) # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã, –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ –≤ —Å–∏–º–≤–æ–ª—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, dataloader, model, criterion, optimizer, max_epochs):\n",
    "  model.train() # –ø–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "  losses = []\n",
    "  for epoch in range(max_epochs):\n",
    "    print(f'\\nEpoch {epoch+1}')\n",
    "    epoch_loss = 0\n",
    "    for batch, (x,y) in enumerate(dataloader):\n",
    "      optimizer.zero_grad()\n",
    "      y_pred, (state_h, state_c) = model(x) # –ø–µ—Ä–µ–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –º–æ–¥–µ–ª—å, –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ\n",
    "      loss = criterion(y_pred.transpose(1,2), y) # —Å—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫—É\n",
    "      epoch_loss += loss.item()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if (batch+1) % 100 == 0:\n",
    "        print(inference(dataset, model))\n",
    "\n",
    "    print(f'Loss {epoch_loss/(batch+1)}')\n",
    "    losses.append(epoch_loss/(batch+1))\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –º–æ–¥–µ–ª—å, –æ–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å, –º–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "model = LM(len(dinos_dataset.char2id)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.2)\n",
    "max_epochs = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–ø—É—Å—Ç–∏–º –æ–±—É—á–µ–Ω–∏–µ. –ë—É–¥–µ–º –∑–∞–ø–∏—Å—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –æ—à–∏–±–∫–∏ –∏ –≤—ã–≤–æ–¥–∏—Ç—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train(dinos_dataset,dinos_dataloader, model, criterion, optimizer, max_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.title('Cross Entropy Loss value')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ—Ü–µ–Ω–∫–∏ —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è. –û–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –º–æ–¥–µ–ª—å –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç –∏—Å—Ç–∏–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π, –ª–µ–∂–∞—â–µ–µ –≤ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö. –ß–µ–º –º–µ–Ω—å—à–µ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è, —Ç–µ–º –ª—É—á—à–µ –º–æ–¥–µ–ª—å.\n",
    "\n",
    "[[blog] ‚úèÔ∏è –ß—Ç–æ —Ç–∞–∫–æ–µ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è?](https://training.continuumlabs.ai/data/datasets/what-is-perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∞—è –≤–∞–∂–Ω–∞—è –∑–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ ‚Äî –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –æ–¥–Ω–æ–º —è–∑—ã–∫–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞ –¥—Ä—É–≥–æ–º —è–∑—ã–∫–µ, –ø–µ—Ä–µ–¥–∞—é—â–∞—è —Ç–æ—Ç –∂–µ —Å–º—ã—Å–ª.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –ø–µ—Ä–µ–≤–æ–¥–∞ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑—Å–∫–∏–π —è–∑—ã–∫:\n",
    "- –ò—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: I am a student.\n",
    "- –¶–µ–ª–µ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ: Je suis √©tudiant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/machine_translation.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞?\n",
    "1. –ü–æ–Ω–∏–º–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞\n",
    "2. –ü–æ–Ω–∏–º–∞—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ (—Å–∏–Ω—Ç–∞–∫—Å–∏—Å)\n",
    "3. –ü–µ—Ä–µ–≤–æ–¥–∏—Ç—å —Å–ª–æ–≤–∞ (—Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)\n",
    "4. –°–æ—Å—Ç–∞–≤–ª—è—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –∏ —Å–≤—è–∑–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "\n",
    "–î–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤, –∑–∞—Ç–µ–º –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å –µ–≥–æ –ø–æ —Ñ—Ä–∞–∑–∞–º.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ —É —Ç–∞–∫–æ–≥–æ –ø–æ–¥—Ö–æ–¥–∞ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã:\n",
    "- –æ–¥–Ω–æ–º—É —Å–ª–æ–≤—É –≤ –∏—Å—Ö–æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ (*forced*) –º–æ–∂–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ –≤ —Ü–µ–ª–µ–≤–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏ (*a forc√©*)\n",
    "- –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤ –º–æ–∂–µ—Ç –º–µ–Ω—è—Ç—å—Å—è (*exceptional measures* vs. *des mesures exceptionnelles*)\n",
    "\n",
    "–°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –≤–æ–∑–Ω–∏–∫–∞—é—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ–º –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è —Å–ª–æ–≤ (word alignment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L04/out/word_alignment.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î—Ä—É–≥–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å ‚Äî –ø—Ä–æ—á–∏—Ç–∞—Ç—å –≤—Å–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Ü–µ–ª–∏–∫–æ–º, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–µ, –∞ –∑–∞—Ç–µ–º –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –ø–µ—Ä–µ–≤–æ–¥.\n",
    "\n",
    "–í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –º–æ–¥–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö –±–ª–æ–∫–æ–≤:\n",
    "- –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫: —Å—Ç—Ä–æ–∏—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–∫–æ–¥–∏—Ä—É–µ—Ç);\n",
    "- –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ü–µ–ª–µ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è (—Ä–∞—Å–∫–æ–¥–∏—Ä—É–µ—Ç)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/encoder_decoder.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://blog.paperspace.com/introduction-to-neural-machine-translation-with-bahdanaus-attention/\">Introduction to Neural Machine Translation</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∑–∞–¥–∞—á–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –¥—Ä—É–≥—É—é, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π –∏ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–ª–∂–Ω–∞ —Å–æ–≤–ø–∞–¥–∞—Ç—å: \"–º–Ω–æ–≥–∏–µ –∫–æ –º–Ω–æ–≥–∏–º\" –∏–ª–∏ sequence-to-sequence (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω–æ seq2seq)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫-–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –±–ª–æ–∫–∞ <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font> –∏ <font color=\"#9b2c6a\">–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/enc_dec-min.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ <font color=\"#5b9b2c\"> –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ </font>:\n",
    "\n",
    "- –Ω–∞ –≤—Ö–æ–¥ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏ RNN –ø–æ—Å—Ç—É–ø–∞–µ—Ç –Ω—É–ª–µ–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "- –µ–≥–æ –≤–µ–∫—Ç–æ—Ä –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_1.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –Ω–∞ –≤—Ö–æ–¥ –≤—Ç–æ—Ä–æ–π —è—á–µ–π–∫–∏ RNN –ø–æ—Å—Ç—É–ø–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–Ø\" –∏ –Ω—É–ª–µ–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "- –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–Ø\" –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –≤—Ç–æ—Ä–æ–π —è—á–µ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_2.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –Ω–∞ –≤—Ö–æ–¥ —Ç—Ä–µ—Ç—å–µ–π —è—á–µ–π–∫–∏ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–≤–∏–¥–µ–ª\" –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–Ø\" –∫–∞–∫ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "- –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"–≤–∏–¥–µ–ª\" –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —Ç—Ä–µ—Ç—å–µ–π —è—á–µ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_3.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —Ç–æ –∂–µ —Å–∞–º–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–æ –≤—Å–µ–º–∏ —Å–ª–æ–≤–∞–º–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_4.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –≤–µ–∫—Ç–æ—Ä —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–∞ \\<eos\\>, –æ–±–æ–∑–Ω–∞—á–∞—é—â–µ–≥–æ –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–π —è—á–µ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;\n",
    "- –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–∞ \\<eos\\> (= –≤–µ–∫—Ç–æ—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –ø–æ—Å—Ç—É–ø–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –∫–∞–∫ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_5.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –î–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ <font color=\"#9b2c6a\"> –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font>:\n",
    "- –Ω–∞ –≤—Ö–æ–¥ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –Ω—É–ª–µ–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏ –≤–µ–∫—Ç–æ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –∫–∞–∫ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "- –æ–Ω–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_6.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –Ω—É–ª–µ–≤–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è softmax;\n",
    "- –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ —Ä–∞–≤–Ω–∞ –¥–ª–∏–Ω–µ —Å–ª–æ–≤–∞—Ä—è, ‚Äî —ç—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ —Ç–µ–∫—É—â–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_7.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_8.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞ —Ç–∞–∫, —á—Ç–æ–±—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –±—ã–ª–∞ –≤—ã—à–µ, –∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ ‚Äî –Ω–∏–∂–µ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_9.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∏ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Ç–æ–∫–µ–Ω—É;\n",
    "- –Ω–∞ –≤—Ö–æ–¥ –≤—Ç–æ—Ä–æ–π —è—á–µ–π–∫–∏ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"I\" –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –Ω—É–ª–µ–≤–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è;\n",
    "- –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"I\" –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ –≤—Ç–æ—Ä–æ–π —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_10.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"I\" –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è softmax, –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_11.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ–ª—É—á–µ–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º, –ø–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –≤–µ—Å–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_12.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —Ç–æ –∂–µ —Å–∞–º–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–æ –≤—Å–µ–º–∏ —Å–ª–æ–≤–∞–º–∏;\n",
    "- –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º 8 –≤–µ–∫—Ç–æ—Ä–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_13.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Ç–∞–∫,\n",
    "- <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫</font> –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;\n",
    "-  <font color=\"#9b2c6a\">–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫</font> –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;\n",
    "- –≤–µ–∫—Ç–æ—Ä –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –Ω–∞ –ø–µ—Ä–≤–æ–º —à–∞–≥–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/seq2seq_14.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ–±–ª–µ–º–∞ Sequence-to-Sequence**: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –∫–æ–Ω–µ—á–Ω–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font> –¥–ª—è –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–π –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –ø–æ—Ç–µ—Ä–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –æ—Å–æ–±–µ–Ω–Ω–æ —Å –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏;\n",
    "- –ø–æ –º–µ—Ä–µ —Ç–æ–≥–æ, –∫–∞–∫ <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫</font> –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Ö–æ–¥–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –æ–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –≤ –∫–æ–Ω–µ—á–Ω–æ–º —Å–∫—Ä—ã—Ç–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –±—É–¥–µ—Ç —Å–æ–±—Ä–∞–Ω–∞ –≤—Å—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è;\n",
    "- –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –¥–ª–∏–Ω–Ω–µ–µ, —ç—Ç–æ–º—É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é —Ç—Ä—É–¥–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —á–∞—Å—Ç–µ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/bottleneck.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —Ä–∞–∑–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫—É –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ö–æ–¥–Ω—ã—Ö –ª–µ–∫—Å–µ–º–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –±–æ–ª–µ–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã –Ω–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ. –î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤–Ω–∏–º–∞–Ω–∏—è: –æ–Ω–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, –∫–∞–∫–∏–µ –∏—Å—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞ –æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è \"–≤–∞–∂–Ω–µ–µ\" –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ü–µ–ª–µ–≤–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_matrices.jpg\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/1409.0473\">Neural Machine Translation by Jointly Learning to Align and Translate</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ –≤—Å–µ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è, –±—ã–ª –ø—Ä–µ–¥–ª–æ–∂–µ–Ω –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è (attention mechanism).\n",
    "\n",
    "[[paper] üéì Bahdanau D., Cho K., Bengio Y. (2014). Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "–ù–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ <font color=\"#9b2c6a\">–¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è</font> –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è —Ä–µ—à–∞–µ—Ç, –∫–∞–∫–∏–µ —á–∞—Å—Ç–∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —è–≤–ª—è—é—Ç—Å—è –±–æ–ª–µ–µ –≤–∞–∂–Ω—ã–º–∏. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫—É</font> –Ω–µ –Ω—É–∂–Ω–æ —Å–∂–∏–º–∞—Ç—å –≤—Å–µ –∏—Å—Ö–æ–¥–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ –æ–¥–∏–Ω –≤–µ–∫—Ç–æ—Ä ‚Äî –æ–Ω –≤—ã–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤, –≤—Å–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_1.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ <font color=\"#5b9b2c\">–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font> –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è, –≤—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—Å–∞—é—Ç—Å—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã <font color=\"#9b2c6a\">–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞</font>.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ—à–∞–≥–æ–≤–æ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–ª–æ–≤–∞ \"–∞\":\n",
    "\n",
    "- –Ω–∞ –≤—Ö–æ–¥ —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –ø–æ—Å—Ç—É–ø–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"a\" –∏ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"saw\" –∫–∞–∫ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ;\n",
    "- –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"a\" –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞;\n",
    "- –≤—ã—Ö–æ–¥ —è—á–µ–π–∫–∏ –¥–µ–∫–æ–¥–µ—Ä–æ–≤—â–∏–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Å–ª–æ–≤—É \"a\", —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è —Å –≤—ã—Ö–æ–¥–æ–º –ø–µ—Ä–≤–æ–π —è—á–µ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–π —Å–ª–æ–≤—É \"–Ø\", —Å –ø–æ–º–æ—â—å—é –Ω–µ–∫–æ—Ç–æ—Ä–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_2.png\" width=\"450\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞—è –º–µ—Ä–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ —Å—á–∏—Ç–∞–µ—Ç—Å—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∞ —Å–ª–æ–≤–∞ \"a\" –∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_3.png\" width=\"450\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —á—Ç–æ–±—ã –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ –≤–µ—Å–∞, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è softmax ‚Äî —Ç–µ–ø–µ—Ä—å –∏—Ö —Å—É–º–º–∞ —Ä–∞–≤–Ω–∞ 1;\n",
    "- –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è –≤–µ—Å–∞–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è (attention weights): –µ—Å–ª–∏ –≤–µ–∫—Ç–æ—Ä—ã –Ω–µ–∫–æ—Ç–æ—Ä–æ–≥–æ —Å–ª–æ–≤–∞ —Ü–µ–ª–µ–≤–æ–≥–æ –∏ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å—Ö–æ–∂–∏, —Ç–æ –≤–µ—Å –≤–Ω–∏–º–∞–Ω–∏—è –±—É–¥–µ—Ç –±–æ–ª—å—à–∏–º, –∏ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ (–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏) –¥–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –±–æ–ª—å—à–µ \"–æ–±—Ä–∞—â–∞–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è\" –Ω–∞ –Ω–µ–≥–æ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_4.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –≤–µ–∫—Ç–æ—Ä –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ —Å–≤–æ–π –≤–µ—Å –≤–Ω–∏–º–∞–Ω–∏—è, –∑–∞—Ç–µ–º –≤—Å–µ –≤–µ–∫—Ç–æ—Ä—ã —Å–∫–ª–∞–¥—ã–≤–∞—é—Ç—Å—è, –ø–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä (attention output);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_5.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –≤–µ–∫—Ç–æ—Ä —Å–ª–æ–≤–∞ \"a\" –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É—é—Ç—Å—è;\n",
    "- –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –Ω–∞ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π, –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è softmax;\n",
    "- –ø–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä, –¥–ª–∏–Ω–∞ –∫–æ—Ç–æ—Ä–æ–≥–æ —Ä–∞–≤–Ω–∞ –¥–ª–∏–Ω–µ —Å–ª–æ–≤–∞—Ä—è, ‚Äî —ç—Ç–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–∞ –Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_6.png\" width=\"650\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- —Ç–æ –∂–µ —Å–∞–º–æ–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–æ –≤—Å–µ–º–∏ —Å–ª–æ–≤–∞–º–∏;\n",
    "- –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ–º 8 –≤–µ–∫—Ç–æ—Ä–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/attention_7.png\" width=\"750\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html\">NLP Course For You</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–∏–º–µ—Ä —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–∞—Ç–µ—Ä–∏–∞–ª –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ [–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ PyTorch üõ†Ô∏è[doc]](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞, —á—Ç–æ–±—ã –ø–æ–∑–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ç–∞—Ä–≥–µ—Ç–æ–≤. –°–¥–µ–ª–∞–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–ª–∞—Å—Å `Lang` –∏–∑ —Å–ª–æ–≤–∞—Ä–µ–π **—Å–ª–æ–≤–æ ‚Üí –∏–Ω–¥–µ–∫—Å** (`word2index`) **–∏ –∏–Ω–¥–µ–∫—Å ‚Üí —Å–ª–æ–≤–æ** (`index2word`), –∞ —Ç–∞–∫–∂–µ —Å—á–µ—Ç—á–∏–∫ –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞ `word2count`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è –∑–∞–º–µ–Ω—ã —Ä–µ–¥–∫–∏—Ö —Å–ª–æ–≤ –ø–æ–∑–∂–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -q -U transformers accelerate git+https://github.com/huggingface/peft.git\n",
    "!pip install -q sentencepiece sentence_transformers\n",
    "!pip install -q -U datasets huggingface-hub\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å–µ —Ñ–∞–π–ª—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Unicode, –ø–æ—ç—Ç–æ–º—É –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –º—ã –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∏–º–≤–æ–ª—ã Unicode –≤ ASCII, —Å–¥–µ–ª–∞–µ–º —Å—Ç—Ä–æ—á–Ω—ã–º–∏ –∏ —É–±–µ—Ä—ë–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return \"\".join(\n",
    "        c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def normalizeStringRu(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-—è–ê-–Ø!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º seeds –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–µ–ª–∏–º —Ñ–∞–π–ª –Ω–∞ —Å—Ç—Ä–æ–∫–∏, –∞ —Å—Ç—Ä–æ–∫–∏ ‚Äî –Ω–∞ –ø–∞—Ä—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.manythings.org/anki/\n",
    "!wget -q https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/datasets/eng_rus_vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = (\n",
    "        open(\"%s_%s_vocab.txt\" % (lang1, lang2), encoding=\"utf-8\")\n",
    "        .read()\n",
    "        .strip()\n",
    "        .split(\"\\n\")\n",
    "    )\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [l.split(\"\\t\")[:2] for l in lines]\n",
    "    eng = [normalizeString(s[0]) for s in pairs]\n",
    "    rus = [normalizeStringRu(s[1]) for s in pairs]\n",
    "    pairs = list(zip(rus, eng))\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å–æ–∫—Ä–∞—Ç–∏–º –¥–∞—Ç–∞—Å–µ—Ç –¥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–µ –¥–ª–∏–Ω–µ–µ 10 —Å–ª–æ–≤ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \",\n",
    "    \"i m \",\n",
    "    \"he is\",\n",
    "    \"he s \",\n",
    "    \"she is\",\n",
    "    \"she s \",\n",
    "    \"you are\",\n",
    "    \"you re \",\n",
    "    \"we are\",\n",
    "    \"we re \",\n",
    "    \"they are\",\n",
    "    \"they re \",\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return (\n",
    "        len(p[0].split(\" \")) < max_length\n",
    "        and len(p[1].split(\" \")) < max_length\n",
    "        and p[1].startswith(eng_prefixes)\n",
    "    )\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –≤ –Ω–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –¥–≤–∞ —Å–ª–æ–≤–∞—Ä—è –∏ –Ω–∞–±–æ—Ä –ø–∞—Ä —Å—Ç—Ä–æ–∫.\n",
    "\n",
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã –Ω–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –≤—Ö–æ–¥–Ω–æ–π —Ç–µ–Ω–∑–æ—Ä (–∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤–æ –≤—Ö–æ–¥–Ω–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏) –∏ —Ü–µ–ª–µ–≤–æ–π —Ç–µ–Ω–∑–æ—Ä (–∏–Ω–¥–µ–∫—Å—ã —Å–ª–æ–≤ –≤ —Ü–µ–ª–µ–≤–æ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏). –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç—Ç–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –º—ã –¥–æ–±–∞–≤–∏–º —Ç–æ–∫–µ–Ω EOS –∫ –æ–±–µ–∏–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "\n",
    "def get_dataloaders(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData(\"eng\", \"rus\", False)\n",
    "\n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, max_length), dtype=np.int32)\n",
    "    target_ids = np.zeros((n, max_length), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, : len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, : len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    # Prepare train/val/test split of sentance pairs\n",
    "    all_pairs_idx = np.random.permutation(len(input_ids))\n",
    "    train_len = int(0.8 * len(input_ids))\n",
    "    val_len = int(0.15 * len(input_ids))\n",
    "    train_pairs, val_pairs, test_pairs = np.split(\n",
    "        ary=all_pairs_idx, indices_or_sections=[train_len, train_len + val_len]\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    datasets = {}\n",
    "    for split, pair_ids in zip(\n",
    "        [\"train\", \"val\", \"test\"], [train_pairs, val_pairs, test_pairs]\n",
    "    ):\n",
    "        datasets[split] = TensorDataset(\n",
    "            torch.LongTensor(input_ids[pair_ids, ...]),\n",
    "            torch.LongTensor(target_ids[pair_ids, ...]),\n",
    "        )\n",
    "    # Prepare dataloaders\n",
    "    train_dataloader = DataLoader(\n",
    "        datasets[\"train\"], batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(datasets[\"val\"], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    test_dataloader = DataLoader(datasets[\"test\"], batch_size=batch_size, shuffle=False)\n",
    "    return (\n",
    "        input_lang,\n",
    "        output_lang,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test_dataloader,\n",
    "        test_pairs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ö–æ–¥–∏—Ä–æ–≤—â–∏–∫-–¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–µ–∫–æ–¥–µ—Ä—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω –∏ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ù–∞—á–∞–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ç–æ–∫–µ–Ω ‚Äî —Ç–æ–∫–µ–Ω –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏ <SOS>, –ø–µ—Ä–≤–æ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚Äî –≤–µ–∫—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.forward_step(\n",
    "                decoder_input, decoder_hidden\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return (\n",
    "            decoder_outputs,\n",
    "            decoder_hidden,\n",
    "            None,\n",
    "        )  # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–ª–æ–π Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–Ω–∞—á–∞–ª–∞ –º—ã –≤—ã—á–∏—Å–ª—è–µ–º **–Ω–∞–±–æ—Ä –≤–µ—Å–æ–≤ Attention**. –û–Ω–∏ –±—É–¥—É—Ç —É–º–Ω–æ–∂–µ–Ω—ã –Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —ç–Ω–∫–æ–¥–µ—Ä–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–π –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏. –†–µ–∑—É–ª—å—Ç–∞—Ç –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç—Ç–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —á–∞—Å—Ç–∏ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ–º–æ–≥–∞—Ç—å –¥–µ–∫–æ–¥–µ—Ä—É –≤—ã–±–∏—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –≤—ã—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–≤–∞.\n",
    "\n",
    "–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ Attention –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è. –í –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤—Å–µ—Ö —Ä–∞–∑–º–µ—Ä–æ–≤, –∏ –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ —Å–ª–æ—è –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –í –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤—Å–µ –≤–µ—Å–∞ –≤–Ω–∏–º–∞–Ω–∏—è, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –≤ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ.\n",
    "\n",
    "$\\large a(h, h') = \\color{red}{w}^T\\tanh(\\color{red}{U}h + \\color{red}{V}h')$ ‚Äî –∞–¥–¥–∏—Ç–∏–≤–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ —Å $\\color{red}{w, U, V}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(\n",
    "            batch_size, 1, dtype=torch.long, device=device\n",
    "        ).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(max_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)  # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(\n",
    "                    -1\n",
    "                ).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –º—ã –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫ –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≤—ã—Ö–æ–¥ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ó–∞—Ç–µ–º –¥–µ–∫–æ–¥–µ—Ä –ø–æ–ª—É—á–∞–µ—Ç —Ç–æ–∫–µ–Ω <SOS> –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–≤–æ–≥–æ –≤—Ö–æ–¥–∞ –∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–∫—Ä—ã—Ç–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q lightning tbparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "class Seq2SeqPipeline(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        exp_name=\"baseline\",\n",
    "        criterion=nn.NLLLoss(),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(\n",
    "            chain(self.encoder.parameters(), self.decoder.parameters()), lr=0.001\n",
    "        )\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_tensor, target_tensor = batch\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = self.decoder(\n",
    "            encoder_outputs, encoder_hidden, target_tensor\n",
    "        )\n",
    "\n",
    "        loss = self.criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "\n",
    "        self.log(\"Loss/train\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_tensor, target_tensor = batch\n",
    "\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = self.decoder(\n",
    "            encoder_outputs, encoder_hidden, target_tensor\n",
    "        )\n",
    "\n",
    "        loss = self.criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)), target_tensor.view(-1)\n",
    "        )\n",
    "\n",
    "        self.log(\"Loss/val\", loss, prog_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512\n",
    "batch_size = 256\n",
    "\n",
    "(\n",
    "    input_lang,\n",
    "    output_lang,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    test_dataloader,\n",
    "    test_pair_ids,\n",
    ") = get_dataloaders(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –∑–∞–Ω–∏–º–∞–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 8 –º–∏–Ω—É—Ç –Ω–∞ GPU. –í —Ü–µ–ª—è—Ö —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ–º —ç—Ç—É —á–∞—Å—Ç—å –∫–æ–¥–∞ –∏ –∑–∞–≥—Ä—É–∑–∏–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–î–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Å—Ç—Ä–æ—á–∫—É –≤ –∫–æ–¥–µ –∏ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "L.seed_everything(42)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"Loss/val\", mode=\"min\", filename=\"best\")\n",
    "\n",
    "exp_name = f\"baseline\"\n",
    "trainer = Trainer(\n",
    "    max_epochs=80,\n",
    "    logger=TensorBoardLogger(save_dir=f\"logs/seq2seq\", name=exp_name),\n",
    "    num_sanity_val_steps=1,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "\n",
    "\n",
    "pipeline = Seq2SeqPipeline(encoder=encoder, decoder=decoder)\n",
    "\n",
    "\"\"\"\n",
    "trainer.fit(\n",
    "    model=pipeline,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://edunet.kea.su/repo/EduNet_NLP-content/L04/weights/logs.zip\n",
    "!unzip -q logs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tbparse import SummaryReader\n",
    "\n",
    "\n",
    "def tbparse_visual(log_path):\n",
    "    reader = SummaryReader(log_path)\n",
    "    df = reader.scalars\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for tag in df.tag.unique():\n",
    "        if \"Loss\" in tag:\n",
    "            tag_data = df.query(\"tag == @tag\").sort_values(by=\"step\")\n",
    "            plt.plot(tag_data.step, tag_data.value, label=tag)\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = f\"/content/logs/seq2seq/{exp_name}\"\n",
    "last_version = sorted(os.listdir(base_path))[-1]\n",
    "log_path = f\"{base_path}/{last_version}\"\n",
    "\n",
    "tbparse_visual(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –º–æ–¥–µ–ª–∏ –∏–∑ –ª—É—á—à–µ–π –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Ç–æ—á–∫–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = f\"{log_path}/checkpoints/best.ckpt\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=device)\n",
    "\n",
    "print(f\"Checkpoint has been loaded from {ckpt_path}\")\n",
    "print(f\"Best model has been saved on the {checkpoint['epoch']} epoch\")\n",
    "\n",
    "state_dict_encoder = {}\n",
    "state_dict_decoder = {}\n",
    "for key in checkpoint[\"state_dict\"].keys():\n",
    "    if key.startswith(\"encoder.\"):\n",
    "        state_dict_encoder[key[len(\"encoder.\") :]] = checkpoint[\"state_dict\"][key]\n",
    "    elif key.startswith(\"decoder.\"):\n",
    "        state_dict_decoder[key[len(\"decoder.\") :]] = checkpoint[\"state_dict\"][key]\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "encoder.load_state_dict(state_dict_encoder)\n",
    "decoder.load_state_dict(state_dict_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Å–æ–∑–¥–∞—ë—Ç –ø–µ—Ä–µ–≤–æ–¥ –∏ attention, –æ–±—Ä–∞—â–∞—è—Å—å –≤–Ω–∞—á–∞–ª–µ –∫ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫—É, –∞ –∑–∞—Ç–µ–º –∫ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫—É:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor.to(device))\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(\n",
    "            encoder_outputs.to(device), encoder_hidden.to(device)\n",
    "        )\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append(\"<EOS>\")\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –º–æ–∂–µ–º –æ—Ü–µ–Ω–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ –æ–±—É—á–∞—é—â–µ–≥–æ –Ω–∞–±–æ—Ä–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    eng = []\n",
    "    dnn = []\n",
    "    for i in range(n):\n",
    "        pair_id = random.choice(test_pair_ids)\n",
    "        pair = pairs[pair_id]\n",
    "        print(\"RUS\", pair[0])\n",
    "        print(\"ENG\", pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        eng.append(pair[1])\n",
    "        dnn.append(output_words[:-1])  # remove <eos> token\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        output_sentence = \" \".join(output_words)\n",
    "        print(\"DNN\", output_sentence)\n",
    "        print(\"\")\n",
    "    return eng, dnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "eng, dnn = evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.cpu().numpy(), cmap=\"bone\")\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_yticks(ax.get_yticks().tolist()[1:-1])\n",
    "    ax.set_xticks(ax.get_xticks().tolist()[1:-1])\n",
    "\n",
    "    ax.set_xticklabels(input_sentence.split(\" \") + [\"<EOS>\"], rotation=90)\n",
    "    ax.set_yticklabels(output_words)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder, decoder, input_sentence, input_lang, output_lang\n",
    "    )\n",
    "    print(\"input =\", input_sentence)\n",
    "    print(\"output =\", \" \".join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions[0, : len(output_words), :])\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"—è —Ä–∞–¥ —á—Ç–æ —É —Ç–µ–±—è –≤—Å–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¶–∏–∫–ª –ø–æ—Å—Ç–æ–≤ –æ–± —ç–≤–æ–ª—é—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞:\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 1](https://habr.com/ru/articles/745642/)\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 2](https://habr.com/ru/articles/748496/)\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 3](https://habr.com/ru/articles/758522/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–ª–æ–±–∞–ª—å–Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –º–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ **—Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ** –∏ **–Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ**.\n",
    "\n",
    "1. –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç—ã –≤ —Ä–∞—Å—á–µ—Ç–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã, –Ω–∞–∏–±–æ–ª–µ–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏–∑ –Ω–∏—Ö —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã –¥–æ –±—É–º–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π. –ß–∞—â–µ –≤—Å–µ–≥–æ —Ç–∞–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ –ø–æ–¥—Å—á–µ—Ç–µ —á–∏—Å–ª–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π —Å–∏–º–≤–æ–ª–æ–≤ / —Å–ª–æ–≤ / c–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π ‚Äî –∏—Ö –Ω–∞–∑—ã–≤–∞—é—Ç ¬´lexic overlap metrics¬ª.\n",
    "\n",
    "2. –ë–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –º–µ—Ç—Ä–∏–∫, –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ 2016 –≥–æ–¥–∞, ‚Äî –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ. –ü–µ—Ä–≤—ã–º —à–∞–≥–æ–º –≤ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –≤ —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å–ª–æ–≤ (embeddings).\n",
    "\n",
    "- –°–Ω–∞—á–∞–ª–∞ **–±–ª–∏–∑–æ—Å—Ç—å embeddings** –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –æ—Ü–µ–Ω–∏–≤–∞–ª–∞—Å—å  **—ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏** (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –º–µ—Ç—Ä–∏–∫ WMD, BERTScore, YiSi).\n",
    "\n",
    "- –î–∞–ª–µ–µ –ø–æ—è–≤–∏–ª–∏—Å—å **–Ω–µ–π—Ä–æ—Å–µ—Ç–∏, –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏** –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏–Ω–∏–º–∞—é—Ç –Ω–∞ –≤—Ö–æ–¥ embeddings –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–æ–≤, –∞ **–Ω–∞ –≤—ã—Ö–æ–¥–µ –¥–∞—é—Ç –æ—Ü–µ–Ω–∫—É** –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ (—Ç–∞–∫–∏–µ –∫–∞–∫ BLEURT, Prism).\n",
    "\n",
    "- –ó–∞—Ç–µ–º –≤–æ–∑–Ω–∏–∫–ª–∏ –º–æ–¥–µ–ª–∏, **–Ω–∞ –≤—Ö–æ–¥** –∫–æ—Ç–æ—Ä—ã—Ö, –ø–æ–º–∏–º–æ –º–∞—à–∏–Ω–Ω–æ–≥–æ –∏ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, **—Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å—Å—è –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫** ‚Äì –æ—Ä–∏–≥–∏–Ω–∞–ª –ø–µ—Ä–µ–≤–æ–¥–∏–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (COMET, UniTE).\n",
    "\n",
    "- –í –ø–∞—Ä–∞–ª–ª–µ–ª—å –≤ —Ä–∞–º–∫–∞—Ö —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ **Quality Estimation** —Ä–∞–∑–≤–∏–≤–∞–ª–∏—Å—å –º–æ–¥–µ–ª–∏, —Å—Ä–∞–≤–Ω–∏–≤–∞—é—â–∏–µ –Ω–∞–ø—Ä—è–º—É—é –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫, –±–µ–∑ —ç—Ç–∞–ª–æ–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞. –¢–∞–∫ –ø–æ—è–≤–∏–ª–æ—Å—å —Ç–æ, —á—Ç–æ –º–æ–∂–Ω–æ –Ω–∞–∑–≤–∞—Ç—å –±–µ–∑—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏ (**reference-free metrics**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L09/nlp_metrics.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/745642/\">–≠–≤–æ–ª—é—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç–æ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç—Ä–∏–∫–∞ BLEU (BiLingual Evaluation Understudy). –û–Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ –ø–æ–¥—Å—á–µ—Ç–µ —Å–ª–æ–≤ (unigrams) –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π (n-grams) –∏–∑ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, —Ç–∞–∫–∂–µ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –≤ —ç—Ç–∞–ª–æ–Ω–µ. –î–∞–ª–µ–µ —ç—Ç–æ —á–∏—Å–ª–æ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ –æ–±—â–µ–µ —á–∏—Å–ª–æ —Å–ª–æ–≤ –∏ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏–π –≤ –º–∞—à–∏–Ω–Ω–æ–º –ø–µ—Ä–µ–≤–æ–¥–µ ‚Äî –ø–æ–ª—É—á–∞–µ—Ç—Å—è precision. –ö –∏—Ç–æ–≥–æ–≤–æ–º—É precision –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–∞ ‚Äî —à—Ç—Ä–∞—Ñ –∑–∞ –∫—Ä–∞—Ç–∫–æ—Å—Ç—å (brevity penalty), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫ BLEU –¥–ª—è –∫—Ä–∞—Ç–∫–∏—Ö –∏ –Ω–µ–ø–æ–ª–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$BLEU=\\text{brevity penalty}‚ãÖ(\\prod_{i=1}^n\\text{precision}_i)^{1/n}‚ãÖ100,$$\n",
    "$$\\text{brevity penalty}=min(1, \\frac{\\text{output length}}{\\text{reference length}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä —Ä–∞—Å—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫–∏ BLEU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L04/bleu_example.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://stepik.org/lesson/262257/step/6\">–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å—á–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ BLEU –¥–ª—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ñ–æ—Ä–º–∞—Ç –ø–æ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –º–µ—Ç—Ä–∏–∫—É. –ü–µ—Ä–≤—ã–º –ø–æ–¥–∞–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞, –≤—Ç–æ—Ä—ã–º ‚Äî —ç—Ç–∞–ª–æ–Ω. –û–Ω–∏ –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å —Ñ–æ—Ä–º–∞—Ç —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫, –ø–æ—ç—Ç–æ–º—É –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º `dnn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_for_bleu = [[\" \".join(x)] for x in dnn]  # Make a string from separated words\n",
    "dnn_for_bleu = [\n",
    "    item for sublist in dnn_for_bleu for item in sublist\n",
    "]  # Make a list from list of lists\n",
    "\n",
    "dnn_for_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torcheval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcheval\n",
    "from torcheval.metrics.functional import bleu_score\n",
    "\n",
    "bleu = bleu_score(dnn_for_bleu, eng)\n",
    "print(f\"BLEU = {bleu.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∑–Ω–∞—á–µ–Ω–∏–µ $n=4$. –ú–æ–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–∏ —Ä–∞–∑–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(2, 5):\n",
    "  bleu = bleu_score(dnn_for_bleu, eng, n_gram=n)\n",
    "  print(f\"BLEU ({n}-gram)= {bleu.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = 6> –ó–∞–∫–ª—é—á–µ–Ω–∏–µ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –ë—ã–ª–∞ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –ø–æ–∑–≤–æ–ª—è—é—â–∞—è —É—á–∏—Ç—ã–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, ‚Äî —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏.\n",
    "- –í—ã—è–≤–ª–µ–Ω—ã –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∏—Ö –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏: LSTM, GRU.\n",
    "- –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω—ã –∑–∞–¥–∞—á–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–≥—É—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è RNN.\n",
    "- –ü–æ–¥—Ä–æ–±–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–æ –¥–≤–µ –∏–∑ –Ω–∏—Ö:\n",
    "  - –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (one-to-many) ‚Äî –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ª–æ–≤;\n",
    "  - –ø–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –¥—Ä—É–≥—É—é (many-to-many) ‚Äî –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6>–õ–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞</font>\n",
    "\n",
    "<font size=5>–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏:</font>\n",
    "* [[article] üìö Long Short-Term Memory (Hochreiter & Schmidhuber, 1997)](http://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "* [[blog] ‚úèÔ∏è Recurrent Neural Networks with PyTorch](https://www.kaggle.com/code/kanncaa1/recurrent-neural-network-with-pytorch)\n",
    "\n",
    "<font size=5>–ü—Ä–∏–º–µ—Ä –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:</font>\n",
    "* [[git] üêæ RNN-walkthrough](https://github.com/gabrielloye/RNN-walkthrough/blob/master/main.ipynb)\n",
    "* [[blog] ‚úèÔ∏è The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "<font size=5>–ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è:</font>\n",
    "* [[paper] üéì Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "\n",
    "<font size=5>–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞:</font>\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 1](https://habr.com/ru/articles/745642/)\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 2](https://habr.com/ru/articles/748496/)\n",
    "- [[blog] ‚úèÔ∏è –ß–∞—Å—Ç—å 3](https://habr.com/ru/articles/758522/)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
